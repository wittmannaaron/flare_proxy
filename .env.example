# LLM Configuration
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=your-api-key
MODEL_NAME=claude-3-sonnet-20240229

# Server configuration
HOST=0.0.0.0
PORT=3128

# Logging
LOG_PATH=/var/log/flare_proxy/flare_proxy.log
LOG_LEVEL=INFO

# ChromaDB
CHROMA_ENDPOINT=http://localhost:1523

# OpenAI API (for embeddings)
OPEN_AI_KEY=your-openai-key
EMBEDDING_MODEL_PREF=text-embedding-3-large

# FLARE settings
CONFIDENCE_THRESHOLD=0.7  # Threshold for additional context retrieval
MAX_RETRIEVAL_ROUNDS=5   # Maximum number of retrieval attempts

# LLM settings
DEFAULT_TEMPERATURE=0.7   # Default sampling temperature if not provided by client
DEFAULT_MAX_TOKENS=4096  # Default max tokens if not provided by client

# Retrieval settings
N_RESULTS=3  # Number of results per collection
MAX_RESULTS=5  # Maximum total number of results
DISTANCE_THRESHOLD=0.5  # Threshold for document relevance (lower = more relevant)
